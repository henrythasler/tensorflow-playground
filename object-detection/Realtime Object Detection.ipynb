{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required modules\n",
    "import cv2\n",
    "import PIL.Image\n",
    "from io import BytesIO\n",
    "import IPython.display\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAME_WIDTH_MODEL = 300\n",
    "FRAME_HEIGHT_MODEL = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use 'jpeg' instead of 'png' (~5 times faster)\n",
    "def showarray(a, prev_display_id=None, fmt='jpeg'):\n",
    "    f = BytesIO()\n",
    "    PIL.Image.fromarray(a).save(f, fmt)\n",
    "    obj = IPython.display.Image(data=f.getvalue())\n",
    "    if prev_display_id is not None:\n",
    "        IPython.display.update_display(obj, display_id=prev_display_id)\n",
    "        return prev_display_id\n",
    "    else:\n",
    "        return IPython.display.display(obj, display_id=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TFLite model and allocate tensors.\n",
    "interpreter = tf.lite.Interpreter(model_path=\"../model-zoo/object-detection/SSD MobileNetV1/lite-model_ssd_mobilenet_v1_1_metadata_2.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "\n",
    "# Load labels\n",
    "with open(\"../model-zoo/object-detection/SSD MobileNetV1/labelmap.txt\", 'r') as f:\n",
    "    labels = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-202ed0e5c76b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mordered\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m                     \u001b[0mclass_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'{} {:.0f}%'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mordered\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mordered\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mputText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFONT_HERSHEY_SIMPLEX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.75\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "# Read the image and decode to a tensor\n",
    "vc = cv2.VideoCapture(0)\n",
    "\n",
    "display_id = None\n",
    "\n",
    "if vc.isOpened(): # try to get the first frame\n",
    "    try:\n",
    "        for i in range(100):\n",
    "            _, frame = vc.read()\n",
    "            \n",
    "            # Convert the image from OpenCV BGR format to matplotlib RGB format\n",
    "            # to display the image\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)        \n",
    "            \n",
    "            frame_squared = frame_rgb[0:480, 80:480+80] \n",
    "            frame_small = cv2.resize(frame_squared,(FRAME_WIDTH_MODEL, FRAME_HEIGHT_MODEL))\n",
    "            #Preprocess the image to required size and cast\n",
    "            input_shape = input_details[0]['shape']\n",
    "            input_tensor= np.array(np.expand_dims(frame_small,0), dtype=np.uint8)            \n",
    "\n",
    "\n",
    "            # Run inference\n",
    "            interpreter.set_tensor(input_index, input_tensor)\n",
    "\n",
    "            #Run the inference\n",
    "            interpreter.invoke()\n",
    "            output_details = interpreter.get_output_details()[0]\n",
    "            output = np.squeeze(interpreter.get_tensor(output_details['index']))\n",
    "\n",
    "            if output_details['dtype'] == np.uint8:\n",
    "                scale, zero_point = output_details['quantization']\n",
    "                output = scale * (output - zero_point)   \n",
    "\n",
    "            ordered = np.argpartition(-output, 1)\n",
    "\n",
    "            canvas = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            cv2.putText(canvas, str(i+1), (3, 15), cv2.FONT_HERSHEY_SIMPLEX, 0.5 , (255, 255, 255), 1)\n",
    "\n",
    "            for j in range(5):\n",
    "                if output[ordered[j]] > 0.:\n",
    "                    class_text = '{} {:.0f}%'.format(labels[ordered[j]], output[ordered[j]]*100) \n",
    "                    cv2.putText(canvas, class_text, (100, 20*(j+1)), cv2.FONT_HERSHEY_SIMPLEX, 0.75 , (0, 255, 0), 2)\n",
    "                \n",
    "            alpha = 0.2\n",
    "            result = cv2.addWeighted(frame_rgb, alpha, canvas, 1 - alpha, 0)\n",
    "            \n",
    "            if display_id is not None:\n",
    "                showarray(result, display_id)\n",
    "            else:\n",
    "                display_id = showarray(result).display_id\n",
    "                \n",
    "            # Display the frame info until new frame is available\n",
    "            IPython.display.clear_output(wait=True)\n",
    "    finally:\n",
    "        vc.release()\n",
    "else:\n",
    "    is_capturing = False\n",
    "    print(\"Camera not found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python38264bita307c9f5d73a4e6bba0d2b5e435e778a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
